{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJD4sdCHd6n1PdMGsuc8q3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanghoonsim/DBA/blob/master/poison_batch_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgeaXxFNVgFj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Loading Data **"
      ],
      "metadata": {
        "id": "PLKwUS6K1pp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "trainsform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "UqLI6S5uWAqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR10('./data', train=False, transform=transform_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhdNNVCkWKu6",
        "outputId": "4f7ad02b-0ac7-4955-fd9a-d7e13f626ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 102213665.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmrIggtSXGBs",
        "outputId": "fa5432a0-4491-463e-8388-d2bed3b14148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdef build_class_dict(): # 10 classes\n",
        "  cifar_classes = {}\n",
        "  for ind, x in enumerate(train_dataset):\n",
        "    _, label = x\n",
        "    if label in cifar_classes:\n",
        "      cifar_classes[label].append(ind)\n",
        "    else:\n",
        "      cifar_classes[label] = [ind]\n",
        "  return cifar_classes"
      ],
      "metadata": {
        "id": "4Qvuk9tiWpqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_dict = build_class_dict()"
      ],
      "metadata": {
        "id": "aC0bgH7Pc3Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_old(all_range, model_no): # model_no: 0~9\n",
        "  data_len = int(len(train_dataset) / 10)\n",
        "  sub_indices = all_range[model_no * data_len : (model_no + 1) * data_len] # 0 : 5000 / 5000: 10000 / ...\n",
        "\n",
        "  # SubsetRandomSampler: take a set of indices and sample the data corresponding to the label\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, sampler=torch.utils.data.sampler.SubsetRandomSampler(sub_indices))\n",
        "  return train_loader\n",
        "\n",
        "def get_test():\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "  return test_loader"
      ],
      "metadata": {
        "id": "PiD6_XkiaLZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_range = list(range(len(train_dataset)))\n",
        "random.shuffle(all_range)\n",
        "train_loader = [(pos, get_train_old(all_range, pos)) for pos in range(100)]"
      ],
      "metadata": {
        "id": "-jImsJyfZHck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_loader\n",
        "test_data = get_test()"
      ],
      "metadata": {
        "id": "Mrz6OkLuZ0Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train_data) : 100\n",
        "range_no_id = list(range(0, len(test_dataset)))\n",
        "len(range_no_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypp5JAn8apls",
        "outputId": "fd102576-c3b5-43af-f11b-ca4eed361574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ptest_classes = {}\n",
        "for ind, x in enumerate(test_dataset):\n",
        "  _, label = x\n",
        "  if label in test_classes:\n",
        "    test_classes[label].append(ind)\n",
        "  else:\n",
        "    test_classes[label] = [ind]"
      ],
      "metadata": {
        "id": "d9uwR7yGZWoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def poison_test_dataset():\n",
        "  test_classes = {}\n",
        "  for ind, x in enumerate(test_dataset):\n",
        "    _, label = x\n",
        "    if label in test_classes:\n",
        "      test_classes[label].append(ind)\n",
        "    else:\n",
        "      test_classes[label] = [ind]\n",
        "      # type(test_classes[0]) = list\n",
        "      # len(test_classes[0]) = 1000\n",
        "      # test_classes.keys() = dict_keys([3, 8, 0, 6, 1, 9, 5, 7, 4, 2])\n",
        "\n",
        "\n",
        "  range_no_id = list(range(0, len(test_dataset))) # list of len 10000\n",
        "\n",
        "  # range_no_id : benign label so remove the poison lable(2)\n",
        "  # append the label '2' into poison_label_inds\n",
        "  for image_ind in test_classes[2]:\n",
        "    if image_ind in range_no_id:\n",
        "      range_no_id.remove(image_ind)\n",
        "  poison_label_inds = test_classes[2]\n",
        "  print(len(range_no_id))\n",
        "  print(len(poison_label_inds))\n",
        "  # SubsetRandomSampler: take a set of indices and sample the data corresponding to the label\n",
        "  return torch.utils.data.DataLoader(test_dataset, batch_size=64, sampler=torch.utils.data.sampler.SubsetRandomSampler(range_no_id)), \\\n",
        "         torch.utils.data.DataLoader(test_dataset, batch_size=64, sampler=torch.utils.data.sampler.SubsetRandomSampler(poison_label_inds))"
      ],
      "metadata": {
        "id": "-AuUn1u8X_PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# not sure why the name is 'test_data_poison', which is benign data to me\n",
        "test_data_poison, test_targetlabel_data = poison_test_dataset()"
      ],
      "metadata": {
        "id": "OqgZo4LPeW5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3595cc56-2916-455d-cb4f-202bb103ef25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adversary_namelist = [17, 33, 77, 11]\n",
        "participants_list = list(range(100))\n",
        "benign_namelist = list(set(participants_list) - set(adversary_namelist))"
      ],
      "metadata": {
        "id": "8yPFWcTDeg9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Model"
      ],
      "metadata": {
        "id": "i8TcmK_411OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import datetime"
      ],
      "metadata": {
        "id": "Arq1cxxF1onq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, name=None, created_time=None):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.created_time = created_time\n",
        "        self.name=name\n",
        "\n",
        "    def train_vis(self, vis, epoch, acc, loss=None, eid='main', is_poisoned=False, name=None):\n",
        "        if name is None:\n",
        "            name = self.name + '_poisoned' if is_poisoned else self.name\n",
        "        vis.line(X=np.array([epoch]), Y=np.array([acc]), name=name, win='train_acc_{0}'.format(self.created_time), env=eid,\n",
        "                                update='append' if vis.win_exists('train_acc_{0}'.format(self.created_time), env=eid) else None,\n",
        "                                opts=dict(showlegend=True, title='Train Accuracy_{0}'.format(self.created_time),\n",
        "                                          width=700, height=400))\n",
        "        if loss is not None:\n",
        "            vis.line(X=np.array([epoch]), Y=np.array([loss]), name=name, env=eid,\n",
        "                                     win='train_loss_{0}'.format(self.created_time),\n",
        "                                     update='append' if vis.win_exists('train_loss_{0}'.format(self.created_time), env=eid) else None,\n",
        "                                     opts=dict(showlegend=True, title='Train Loss_{0}'.format(self.created_time), width=700, height=400))\n",
        "        return\n",
        "\n",
        "    def train_batch_vis(self, vis, epoch, data_len, batch, loss, eid='main', name=None, win='train_batch_loss', is_poisoned=False):\n",
        "        if name is None:\n",
        "            name = self.name + '_poisoned' if is_poisoned else self.name\n",
        "        else:\n",
        "            name = name + '_poisoned' if is_poisoned else name\n",
        "\n",
        "        vis.line(X=np.array([(epoch-1)*data_len+batch]), Y=np.array([loss]),\n",
        "                                 env=eid,\n",
        "                                 name=f'{name}' if name is not None else self.name, win=f'{win}_{self.created_time}',\n",
        "                                 update='append' if vis.win_exists(f'{win}_{self.created_time}', env=eid) else None,\n",
        "                                 opts=dict(showlegend=True, width=700, height=400, title='Train Batch loss_{0}'.format(self.created_time)))\n",
        "    def track_distance_batch_vis(self,vis, epoch, data_len, batch, distance_to_global_model,eid,name=None,is_poisoned=False):\n",
        "        x= (epoch-1)*data_len+batch+1\n",
        "\n",
        "        if name is None:\n",
        "            name = self.name + '_poisoned' if is_poisoned else self.name\n",
        "        else:\n",
        "            name = name + '_poisoned' if is_poisoned else name\n",
        "\n",
        "\n",
        "        vis.line(Y=np.array([distance_to_global_model]), X=np.array([x]),\n",
        "                 win=f\"global_dist_{self.created_time}\",\n",
        "                 env=eid,\n",
        "                 name=f'Model_{name}',\n",
        "                 update='append' if\n",
        "                 vis.win_exists(f\"global_dist_{self.created_time}\",\n",
        "                                env=eid) else None,\n",
        "                 opts=dict(showlegend=True,\n",
        "                           title=f\"Distance to Global {self.created_time}\",\n",
        "                           width=700, height=400))\n",
        "    def weight_vis(self,vis,epoch,weight, eid, name,is_poisoned=False):\n",
        "        name = str(name) + '_poisoned' if is_poisoned else name\n",
        "        vis.line(Y=np.array([weight]), X=np.array([epoch]),\n",
        "                 win=f\"Aggregation_Weight_{self.created_time}\",\n",
        "                 env=eid,\n",
        "                 name=f'Model_{name}',\n",
        "                 update='append' if\n",
        "                 vis.win_exists(f\"Aggregation_Weight_{self.created_time}\",\n",
        "                                env=eid) else None,\n",
        "                 opts=dict(showlegend=True,\n",
        "                           title=f\"Aggregation Weight {self.created_time}\",\n",
        "                           width=700, height=400))\n",
        "\n",
        "    def alpha_vis(self,vis,epoch,alpha, eid, name,is_poisoned=False):\n",
        "        name = str(name) + '_poisoned' if is_poisoned else name\n",
        "        vis.line(Y=np.array([alpha]), X=np.array([epoch]),\n",
        "                 win=f\"FG_Alpha_{self.created_time}\",\n",
        "                 env=eid,\n",
        "                 name=f'Model_{name}',\n",
        "                 update='append' if\n",
        "                 vis.win_exists(f\"FG_Alpha_{self.created_time}\",\n",
        "                                env=eid) else None,\n",
        "                 opts=dict(showlegend=True,\n",
        "                           title=f\"FG Alpha {self.created_time}\",\n",
        "                           width=700, height=400))\n",
        "\n",
        "    def trigger_test_vis(self, vis, epoch, acc, loss, eid, agent_name_key, trigger_name, trigger_value):\n",
        "        vis.line(Y=np.array([acc]), X=np.array([epoch]),\n",
        "                 win=f\"poison_triggerweight_vis_acc_{self.created_time}\",\n",
        "                 env=eid,\n",
        "                 name=f'{agent_name_key}_[{trigger_name}]_{trigger_value}',\n",
        "                 update='append' if vis.win_exists(f\"poison_trigger_acc_{self.created_time}\",\n",
        "                                                   env=eid) else None,\n",
        "                 opts=dict(showlegend=True,\n",
        "                           title=f\"Backdoor Trigger Test Accuracy_{self.created_time}\",\n",
        "                           width=700, height=400))\n",
        "        if loss is not None:\n",
        "            vis.line(Y=np.array([loss]), X=np.array([epoch]),\n",
        "                     win=f\"poison_trigger_loss_{self.created_time}\",\n",
        "                     env=eid,\n",
        "                     name=f'{agent_name_key}_[{trigger_name}]_{trigger_value}',\n",
        "                     update='append' if vis.win_exists(f\"poison_trigger_loss_{self.created_time}\",\n",
        "                                                       env=eid) else None,\n",
        "                     opts=dict(showlegend=True,\n",
        "                               title=f\"Backdoor Trigger Test Loss_{self.created_time}\",\n",
        "                               width=700, height=400))\n",
        "\n",
        "    def trigger_agent_test_vis(self, vis, epoch, acc, loss, eid, name):\n",
        "        vis.line(Y=np.array([acc]), X=np.array([epoch]),\n",
        "                 win=f\"poison_state_trigger_acc_{self.created_time}\",\n",
        "                 env=eid,\n",
        "                 name=f'{name}',\n",
        "                 update='append' if vis.win_exists(f\"poison_state_trigger_acc_{self.created_time}\",\n",
        "                                                   env=eid) else None,\n",
        "                 opts=dict(showlegend=True,\n",
        "                           title=f\"Backdoor State Trigger Test Accuracy_{self.created_time}\",\n",
        "                           width=700, height=400))\n",
        "        if loss is not None:\n",
        "            vis.line(Y=np.array([loss]), X=np.array([epoch]),\n",
        "                     win=f\"poison_state_trigger_loss_{self.created_time}\",\n",
        "                     env=eid,\n",
        "                     name=f'{name}',\n",
        "                     update='append' if vis.win_exists(f\"poison_state_trigger_loss_{self.created_time}\",\n",
        "                                                       env=eid) else None,\n",
        "                     opts=dict(showlegend=True,\n",
        "                               title=f\"Backdoor State Trigger Test Loss_{self.created_time}\",\n",
        "                               width=700, height=400))\n",
        "\n",
        "\n",
        "    def poison_test_vis(self, vis, epoch, acc, loss, eid, agent_name_key):\n",
        "        name= agent_name_key\n",
        "        # name= f'Model_{name}'\n",
        "\n",
        "        vis.line(Y=np.array([acc]), X=np.array([epoch]),\n",
        "                 win=f\"poison_test_acc_{self.created_time}\",\n",
        "                 env=eid,\n",
        "                 name=name,\n",
        "                 update='append' if vis.win_exists(f\"poison_test_acc_{self.created_time}\",\n",
        "                                                   env=eid) else None,\n",
        "                 opts=dict(showlegend=True,\n",
        "                           title=f\"Backdoor Task Accuracy_{self.created_time}\",\n",
        "                           width=700, height=400))\n",
        "        if loss is not None:\n",
        "            vis.line(Y=np.array([loss]), X=np.array([epoch]),\n",
        "                     win=f\"poison_loss_acc_{self.created_time}\",\n",
        "                     env=eid,\n",
        "                     name=name,\n",
        "                     update='append' if vis.win_exists(f\"poison_loss_acc_{self.created_time}\",\n",
        "                                                       env=eid) else None,\n",
        "                     opts=dict(showlegend=True,\n",
        "                               title=f\"Backdoor Task Test Loss_{self.created_time}\",\n",
        "                               width=700, height=400))\n",
        "\n",
        "    def additional_test_vis(self, vis, epoch, acc, loss, eid, agent_name_key):\n",
        "        name = agent_name_key\n",
        "        vis.line(Y=np.array([acc]), X=np.array([epoch]),\n",
        "                 win=f\"additional_test_acc_{self.created_time}\",\n",
        "                 env=eid,\n",
        "                 name=name,\n",
        "                 update='append' if vis.win_exists(f\"additional_test_acc_{self.created_time}\",\n",
        "                                                   env=eid) else None,\n",
        "                 opts=dict(showlegend=True,\n",
        "                           title=f\"Additional Test Accuracy_{self.created_time}\",\n",
        "                           width=700, height=400))\n",
        "        if loss is not None:\n",
        "            vis.line(Y=np.array([loss]), X=np.array([epoch]),\n",
        "                     win=f\"additional_test_loss_{self.created_time}\",\n",
        "                     env=eid,\n",
        "                     name=name,\n",
        "                     update='append' if vis.win_exists(f\"additional_test_loss_{self.created_time}\",\n",
        "                                                       env=eid) else None,\n",
        "                     opts=dict(showlegend=True,\n",
        "                               title=f\"Additional Test Loss_{self.created_time}\",\n",
        "                               width=700, height=400))\n",
        "\n",
        "\n",
        "    def test_vis(self, vis, epoch, acc, loss, eid, agent_name_key):\n",
        "        name= agent_name_key\n",
        "        # name= f'Model_{name}'\n",
        "\n",
        "        vis.line(Y=np.array([acc]), X=np.array([epoch]),\n",
        "                 win=f\"test_acc_{self.created_time}\",\n",
        "                 env=eid,\n",
        "                 name=name,\n",
        "                 update='append' if vis.win_exists(f\"test_acc_{self.created_time}\",\n",
        "                                                   env=eid) else None,\n",
        "                 opts=dict(showlegend=True,\n",
        "                           title=f\"Main Task Test Accuracy_{self.created_time}\",\n",
        "                           width=700, height=400))\n",
        "        if loss is not None:\n",
        "            vis.line(Y=np.array([loss]), X=np.array([epoch]),\n",
        "                     win=f\"test_loss_{self.created_time}\",\n",
        "                     env=eid,\n",
        "                     name=name,\n",
        "                     update='append' if vis.win_exists(f\"test_loss_{self.created_time}\",\n",
        "                                                       env=eid) else None,\n",
        "                     opts=dict(showlegend=True,\n",
        "                               title=f\"Main Task Test Loss_{self.created_time}\",\n",
        "                               width=700, height=400))\n",
        "\n",
        "\n",
        "    def save_stats(self, epoch, loss, acc):\n",
        "        self.stats['epoch'].append(epoch)\n",
        "        self.stats['loss'].append(loss)\n",
        "        self.stats['acc'].append(acc)\n",
        "\n",
        "    def copy_params(self, state_dict, coefficient_transfer=100):\n",
        "\n",
        "        own_state = self.state_dict()\n",
        "\n",
        "        for name, param in state_dict.items():\n",
        "            if name in own_state:\n",
        "                shape = param.shape\n",
        "                #random_tensor = (torch.cuda.FloatTensor(shape).random_(0, 100) <= coefficient_transfer).type(torch.cuda.FloatTensor)\n",
        "                # negative_tensor = (random_tensor*-1)+1\n",
        "                # own_state[name].copy_(param)\n",
        "                own_state[name].copy_(param.clone())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SimpleMnist(SimpleNet):\n",
        "    def __init__(self, name=None, created_time=None):\n",
        "        super(SimpleMnist, self).__init__(name, created_time)\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "gDQA7MZv2EdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(SimpleNet):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, name=None, created_time=None):\n",
        "        super(ResNet, self).__init__(name, created_time)\n",
        "        self.in_planes = 32\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        # for SDTdata\n",
        "        # return F.softmax(out, dim=1)\n",
        "        # for regular output\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(name=None, created_time=None):\n",
        "    return ResNet(BasicBlock, [2,2,2,2],name='{0}_ResNet_18'.format(name), created_time=created_time)\n",
        "\n",
        "def ResNet34(name=None, created_time=None):\n",
        "    return ResNet(BasicBlock, [3,4,6,3],name='{0}_ResNet_34'.format(name), created_time=created_time)\n",
        "\n",
        "def ResNet50(name=None, created_time=None):\n",
        "    return ResNet(Bottleneck, [3,4,6,3],name='{0}_ResNet_50'.format(name), created_time=created_time)\n",
        "\n",
        "def ResNet101(name=None, created_time=None):\n",
        "    return ResNet(Bottleneck, [3,4,23,3],name='{0}_ResNet'.format(name), created_time=created_time)\n",
        "\n",
        "def ResNet152(name=None, created_time=None):\n",
        "    return ResNet(Bottleneck, [3,8,36,3],name='{0}_ResNet'.format(name), created_time=created_time)"
      ],
      "metadata": {
        "id": "PO4g3Qe22KGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_model = ResNet18(name='local')\n",
        "target_model = ResNet18(name='target')"
      ],
      "metadata": {
        "id": "Uyj-nzZp3KVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvjptX2m31o9",
        "outputId": "854ac706-538c-4a29-d485-2e2790c8c632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_model = local_model.to(device)\n",
        "target_model = target_model.to(device)"
      ],
      "metadata": {
        "id": "uhU4M84U4i40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch = 1\n",
        "\n",
        "best_loss = float('inf')\n",
        "\n",
        "def init_weight_accumulator(target_model):\n",
        "  weight_accumulator = dict()\n",
        "  for name, data in target_model.state_dict().items():\n",
        "    weight_accumulator[name] = torch.zeros_like(data)\n",
        "  return weight_accumulator\n",
        "\n",
        "weight_accumulator = init_weight_accumulator(target_model)"
      ],
      "metadata": {
        "id": "aApIcWnn4teZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ImageTrain():\n"
      ],
      "metadata": {
        "id": "zKokzfTHC7oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(start_epoch, local_model, target_model, is_poison,agent_name_keys):\n",
        "    epochs_submit_update_dict={}\n",
        "    num_samples_dict={}\n",
        "    epochs_submit_update_dict, num_samples_dict = ImageTrain(helper, start_epoch, local_model,\n",
        "                                                                             target_model, is_poison, agent_name_keys)\n",
        "    return epochs_submit_update_dict, num_samples_dict"
      ],
      "metadata": {
        "id": "Ac9Z4_eNC1k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "_poison_epochs_0 = [203]\n",
        "_poison_epochs_1 = [205]\n",
        "_poison_epochs_2 = [207]\n",
        "_poison_epochs_3 = [209]\n",
        "\n",
        "for epoch in range(start_epoch, 300+1, 1):\n",
        "  start_time = time.time()\n",
        "  t = time.time()\n",
        "\n",
        "  agent_name_keys = participants_list\n",
        "  adversarial_name_keys = list()\n",
        "\n",
        "  ongoing_epochs = list(range(epoch, epoch + 1))\n",
        "  for idx in range(len(adversary_namelist)):\n",
        "    poison_var_name = f'_poison_epochs_{idx}'\n",
        "    poison_epochs = globals().get(poison_var_name, [])\n",
        "\n",
        "    for ongoing_epoch in ongoing_epochs:\n",
        "      if ongoing_epoch in poison_epochs:\n",
        "        if adversary_namelist[idx] not in adversarial_name_keys:\n",
        "          adversarial_name_keys.append(adversary_namelist[idx])\n",
        "\n",
        "  # attackers who is not the adversarial at this time.\n",
        "  nonattacker = list()\n",
        "  for adv in adversary_namelist:\n",
        "    if adv not in adversarial_name_keys:\n",
        "      nonattacker.append(copy.deepcopy(adv))\n",
        "\n",
        "  benign_num = 10 - len(adversarial_name_keys)\n",
        "  random_agent_name_keys = random.sample(benign_namelist + nonattacker, benign_num) # 100명 중에 Adversary (4명)) 제외하고 나머지 6명 샘플링\n",
        "  agent_name_keys = adversarial_name_keys + random_agent_name_keys\n",
        "\n",
        "  epochs_submit_update_dict, num_samples_dict = train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "Iqia1vtX6kEz",
        "outputId": "e524fe05-ccf5-4fd1-9acf-6f9ff4afde9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train() missing 6 required positional arguments: 'helper', 'start_epoch', 'local_model', 'target_model', 'is_poison', and 'agent_name_keys'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-570278d85481>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0magent_name_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_name_keys\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrandom_agent_name_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mepochs_submit_update_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train() missing 6 required positional arguments: 'helper', 'start_epoch', 'local_model', 'target_model', 'is_poison', and 'agent_name_keys'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tnYXL5JbCRr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_submit_update_dict = dict()\n",
        "num_samples_dict = dict()\n",
        "current_number_of_adversaries = 0\n",
        "for temp_name in agent_name_keys:\n",
        "  if temp_name in adversary_namelist:\n",
        "    current_number_of_adversaries +=1"
      ],
      "metadata": {
        "id": "Br_h9cwwanGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XI6d1OROdQGL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}